{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is linear in a generalized linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GLM typically contrains 3 components\n",
    "1. The probability distribution from exponential family\n",
    "2. The linear predictor\n",
    "3. The link function which connects the mean of 1. to the linear predictor\n",
    "\n",
    "So, the linear part is the linear preditor in GLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the curse of dimensionality mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curse of dimensionality means that when the dimensionality increases, the volume of the space increase so fast that the available data become sparse. This sparsity is problematic for ML methods that require statistical significance. In order to obtain reliable result, the amount of data grows exponentially. Following is a simple example.\n",
    "\n",
    "Let's say you have a straight line 100 yards long and you dropped a penny somewhere on it. It wouldn't be too hard to find. You walk along the line and it takes two minutes.\n",
    "\n",
    "Now let's say you have a square 100 yards on each side and you dropped a penny somewhere on it. It would be pretty hard, like searching across two football fields stuck together. It could take days.\n",
    "\n",
    "Now a cube 100 yards across. That's like searching a 30-story building the size of a football stadium. Ugh.\n",
    "\n",
    "The difficulty of searching through the space gets a lot harder as you have more dimensions. You might not realize this intuitively when it's just stated in mathematical formulas, since they all have the same \"width\". That's the curse of dimensionality. It gets to have a name because it is unintuitive, useful, and yet simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between joint and conditional probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Joint probability measures how likely two (or more) things will both occur\n",
    "+ Conditional probability measure how likely one thing happen if you know the other things has happened. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement logistic regression training for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have m training data points $((x^1, y^1), (x^2, y^2), ... ,(x^m, y^m))$. \n",
    "+ Each x is resent by a n-dimension vector x = $(x_1, x_2, .., x_n)$\n",
    "+ Linear predictor: $p(y=1|x) = y' = f(x)$ where f is the sigmoid function $f = 1/(1 + exp(-w*x))$ and w is the weight vector; $p(y=0|x) = 1-y'$\n",
    "\n",
    "Cross-entropy cost function between predicted value and grouth truth is: $H(y, y') = -y*log(y') - (1-y)log(1-y')$\n",
    "\n",
    "Gradient of the cost function with regard to $i^{th}$ dimension of input vector $x = (y' - y) * x_i$\n",
    "\n",
    "So the loss function over the training data: $L(w) = \\frac{1}{m} \\sum_{j=1,m} {[-y_j*log(y'_j) - (1-y_j)log(1-y'_j)]}$\n",
    "\n",
    "minimize L(w) using gradient descent\n",
    "\n",
    "repeat{    \n",
    "    $w_i = w_i - \\alpha * \\sum_{j=1,m} {(y'_j -y_j)*x_{j,i}}$    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between Naive Bayes and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between linear regression and logistic regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use linear regression when you want to predict continuous outcome. \n",
    "+ Use logistic regression when the outcome is categorical.\n",
    "\n",
    "For example, given X is the number of square feet in a house. If you want to predict what is the selling price of the house you will use linear regression.\n",
    "On the other hand, if you want to predict whether or not the house would sell the house more than $500K you will use logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between generative and discriminative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is maximum likelihood, cost function, gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some alternatives to gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the EM algorithm? Give a couple of applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Explain what regularization is and why it is useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a probabilistic graphical model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between Markov networks and Bayesian networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain decision tree & decision forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain kernel tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix factorization/Model selection/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On what type of ensemble technique is a random forest based? What particular limitation does it try to address?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Ax=b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give an example of an application of non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What methods for dimensionality reduction do you know and how do they compare with each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some good ways for performing feature selection that do not involve exhaustive search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would you evaluate the quality of the clusters that are generated by a run of K-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain A/B testing and give a concrete example how to use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would you validate a model you created to generate a predictive model of a quantitative outcome variable using multiple regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain what precision and recall are. How do they relate to the ROC curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can you prove that one improvement you've brought to an algorithm is really an improvement over not doing anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is it better to have too many false positives, or too many false negatives? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is selection bias, why is it important and how can you avoid it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is root cause analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain price optimization, price elasticity, inventory management, competitive intelligence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain what resampling methods are and why they are useful. Also explain their limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some of the main characteristics that distinguish deep learning from traditional machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between mean square error and cross entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare & contrast CNN & RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP & Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's HMM? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's CRF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's sequence-to-sequence model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare & contrast sequence-to-sequence model with other NLP models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers.html/3\n",
    "    \n",
    "https://www.quora.com/What-are-the-best-interview-questions-to-evaluate-a-machine-learning-researcher\n",
    "\n",
    "http://stats.stackexchange.com/questions/65379/machine-learning-curse-of-dimensionality-explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "684px",
   "left": "1350.23px",
   "right": "20px",
   "top": "20px",
   "width": "549px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
